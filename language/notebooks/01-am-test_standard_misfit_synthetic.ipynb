{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import AdamW\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torchvision.datasets import MNIST, CIFAR10\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from src.params import DATA_DIR\n",
    "from src.models import MLP, TruncatedMLP\n",
    "from src.datasets import SyntheticDataSampler\n",
    "from src.engine import DatasetTrainer, SamplingTrainer\n",
    "from src.metrics import binary_cross_entropy, logistic_bregman_binary, reverse_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the hidden representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset = CIFAR10\n",
    "\n",
    "init_dataset = dataset(\n",
    "    root=DATA_DIR,\n",
    "    download=True,\n",
    "    transform=T.Compose([T.ToTensor(), T.Lambda(lambda x: torch.flatten(x)), T.Lambda(lambda x: (x - x.mean()) / x.std()),]),\n",
    "    target_transform=lambda x: F.one_hot(torch.tensor(x), num_classes=10).to(torch.float32),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 50000\n",
      "Number of classes: 10\n",
      "Sample dim: 3072\n",
      "Target shape: torch.Size([1, 10])\n",
      "Sample Mean: -1.514951435410694e-07\n",
      "Sample Std: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Get some stats on the mnist dataset \n",
    "print(f\"Number of samples: {len(init_dataset)}\")\n",
    "print(f\"Number of classes: {len(init_dataset.classes)}\")\n",
    "\n",
    "tmp_loader = data.DataLoader(init_dataset, batch_size=1, shuffle=True)\n",
    "sample = next(iter(tmp_loader))\n",
    "\n",
    "data_sample_dim = sample[0].shape[1]\n",
    "print(f\"Sample dim: {data_sample_dim}\")\n",
    "print(f\"Target shape: {sample[1].shape}\")\n",
    "print(f\"Sample Mean: {sample[0].mean()}\")\n",
    "print(f\"Sample Std: {sample[0].std()}\")\n",
    "# sample[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = data_sample_dim\n",
    "hidden_dim = 50\n",
    "target_num_layers = 2\n",
    "init_model = MLP(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=len(init_dataset.classes), num_layers=target_num_layers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncation_factor = 0.5\n",
    "weak_num_layers = 2\n",
    "weak_hidden_dim = 50\n",
    "wk_init_model = TruncatedMLP(input_dim=input_dim, hidden_dim=weak_hidden_dim, output_dim=len(init_dataset.classes), num_layers=weak_num_layers, truncation_factor=truncation_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model device for training: cpu\n",
      "Using model device for training: cpu\n",
      "Using model device for training: cpu\n",
      "Using model device for training: cpu\n"
     ]
    }
   ],
   "source": [
    "gt_optimizer = AdamW(init_model.parameters(), lr=1e-3)\n",
    "gt_trainer = DatasetTrainer(init_model, optimizer=gt_optimizer, loss_fn=binary_cross_entropy, dataset=init_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Initializing the ground truth model on {dataset.__name__}\")\n",
    "gt_trainer.train(num_epochs=2, batch_size=64, average_window=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wk_optimizer = AdamW(wk_init_model.parameters(), lr=1e-3)\n",
    "wk_trainer = DatasetTrainer(wk_init_model, optimizer=wk_optimizer, loss_fn=binary_cross_entropy, dataset=init_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing the ground truth model on CIFAR10\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:06<00:00, 124.01it/s, loss=0.236]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:06<00:00, 122.69it/s, loss=0.235]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing the weak model on CIFAR10\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:06<00:00, 123.74it/s, loss=0.254]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:06<00:00, 126.15it/s, loss=0.245]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Initializing the weak model on {dataset.__name__}\")\n",
    "wk_trainer.train(num_epochs=2, batch_size=64, average_window=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do the weak to strong transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the ground truth model. We increase confidence via finetune_scale to lower ground-truth entropy\n",
    "task_output_dim = len(init_dataset.classes)\n",
    "gt_model = MLP(\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    output_dim=task_output_dim,\n",
    "    num_layers=target_num_layers,\n",
    "    finetune_scale=10.0\n",
    ")\n",
    "gt_model.load_state_dict(init_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_model = MLP(\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    output_dim=task_output_dim,\n",
    "    num_layers=target_num_layers,\n",
    "    representation_state_dict=init_model.representation.state_dict(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some sanity-checks\n",
    "assert (\n",
    "    gt_model.representation.state_dict().keys()\n",
    "    == st_model.representation.state_dict().keys()\n",
    ")\n",
    "assert all(\n",
    "    [\n",
    "        torch.all(\n",
    "            gt_model.representation.state_dict()[k]\n",
    "            == st_model.representation.state_dict()[k]\n",
    "        )\n",
    "        for k in gt_model.representation.state_dict().keys()\n",
    "    ]\n",
    ")\n",
    "assert torch.any(gt_model.finetune.weight != st_model.finetune.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the weak model to use the trained weak representations\n",
    "wk_model = TruncatedMLP(\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=weak_hidden_dim,\n",
    "    output_dim=task_output_dim,\n",
    "    num_layers=weak_num_layers,\n",
    "    representation_state_dict=wk_init_model.representation.state_dict(),\n",
    "    truncation_factor=wk_init_model.truncation_factor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model device for synthetic data generation: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataBatch(x=tensor([[ 1.1158, -0.7585,  0.2394,  ...,  1.0146,  0.0405,  0.9326],\n",
       "        [-0.2947, -1.6133,  0.7281,  ...,  1.4950,  0.4876,  1.7895],\n",
       "        [ 0.3170, -0.2431,  1.2137,  ..., -0.9399, -0.0925, -0.3383],\n",
       "        ...,\n",
       "        [-0.8848, -0.8457,  1.9605,  ..., -1.4294, -0.3669,  0.3277],\n",
       "        [ 1.6444, -1.0170,  2.4005,  ..., -0.9120, -1.2872,  0.3513],\n",
       "        [-1.1767,  0.1469,  0.0938,  ..., -0.2114,  1.1745, -0.0937]]), y=tensor([[9.8536e-01, 4.2823e-03, 1.0059e-02, 3.1852e-07, 1.3077e-04, 7.5306e-05,\n",
       "         1.2698e-10, 3.9368e-05, 3.3150e-06, 5.0069e-05],\n",
       "        [5.9405e-01, 2.3071e-02, 1.6340e-02, 3.3485e-02, 1.3879e-02, 2.0578e-01,\n",
       "         4.2260e-02, 7.1515e-04, 6.6332e-02, 4.0903e-03],\n",
       "        [5.4928e-04, 2.5970e-06, 5.6081e-04, 3.3222e-05, 1.4451e-04, 1.8800e-05,\n",
       "         5.5667e-06, 7.1527e-05, 9.9846e-01, 1.5498e-04],\n",
       "        [1.1737e-02, 3.9084e-01, 1.1168e-05, 6.8631e-03, 9.0081e-06, 1.5769e-02,\n",
       "         5.0055e-04, 1.3715e-08, 5.6841e-01, 5.8623e-03],\n",
       "        [1.7878e-02, 6.5159e-04, 9.4063e-01, 9.5856e-04, 4.9334e-03, 2.4508e-03,\n",
       "         2.4463e-04, 3.0684e-03, 2.5770e-02, 3.4145e-03],\n",
       "        [1.1330e-04, 1.1636e-06, 9.4945e-01, 5.1878e-03, 1.3143e-03, 4.3276e-02,\n",
       "         1.3811e-04, 4.9251e-04, 1.5818e-05, 1.0128e-05],\n",
       "        [8.4424e-01, 4.9261e-04, 4.9691e-02, 9.9217e-05, 2.2335e-02, 2.8372e-03,\n",
       "         6.1232e-06, 1.6339e-02, 5.6122e-02, 7.8400e-03],\n",
       "        [3.5899e-01, 2.2684e-03, 1.0709e-01, 1.7286e-02, 9.1515e-03, 1.0011e-02,\n",
       "         4.8817e-01, 5.8741e-03, 1.7120e-04, 9.8488e-04],\n",
       "        [7.8954e-05, 8.5042e-01, 7.9874e-05, 5.3676e-05, 8.8659e-03, 1.9100e-05,\n",
       "         1.0428e-05, 1.3393e-05, 1.3043e-01, 1.0023e-02],\n",
       "        [4.4942e-02, 1.9488e-02, 9.5063e-03, 3.6973e-01, 4.6479e-04, 4.2855e-01,\n",
       "         6.8052e-02, 4.5986e-03, 2.6786e-02, 2.7885e-02]]), y_logits=tensor([[  0.3794,  -5.0592,  -4.2052, -14.5655,  -8.5480,  -9.0998, -22.3929,\n",
       "          -9.7485, -12.2230,  -9.5080],\n",
       "        [ -2.1890,  -5.4374,  -5.7824,  -5.0649,  -5.9456,  -3.2491,  -4.8321,\n",
       "          -8.9112,  -4.3813,  -7.1673],\n",
       "        [ -4.8443, -10.1986,  -4.8235,  -7.6497,  -6.1796,  -8.2191,  -9.4361,\n",
       "          -6.8828,   2.6610,  -6.1097],\n",
       "        [ -7.2210,  -3.7155, -14.1784,  -7.7576, -14.3934,  -6.9257, -10.3758,\n",
       "         -20.8807,  -3.3409,  -7.9152],\n",
       "        [ -3.5920,  -6.9039,   0.3710,  -6.5179,  -4.8795,  -5.5791,  -7.8836,\n",
       "          -5.3544,  -3.2263,  -5.2475],\n",
       "        [ -8.0220, -12.6006,   1.0115,  -4.1980,  -5.5711,  -2.0768,  -7.8241,\n",
       "          -6.5526,  -9.9910, -10.4368],\n",
       "        [ -0.4367,  -7.8832,  -3.2693,  -9.4856,  -4.0690,  -6.1323, -12.2708,\n",
       "          -4.3816,  -3.1476,  -5.1159],\n",
       "        [ -3.6648,  -8.7290,  -4.8744,  -6.6982,  -7.3342,  -7.2444,  -3.3574,\n",
       "          -7.7775, -11.3130,  -9.5633],\n",
       "        [ -9.0397,   0.2449,  -9.0281,  -9.4256,  -4.3186, -10.4589, -11.0641,\n",
       "         -10.8139,  -1.6300,  -4.1960],\n",
       "        [ -3.9235,  -4.7591,  -5.4769,  -1.8161,  -8.4950,  -1.6685,  -3.5086,\n",
       "          -6.2031,  -4.4410,  -4.4008]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = 1.0\n",
    "gt_data_sampler = SyntheticDataSampler(model=gt_model, input_dim=input_dim, output_dim=task_output_dim, var=var)\n",
    "gt_data_sampler.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the weak model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model device for training: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15625/15625 [00:40<00:00, 386.16it/s, loss=0.28] \n"
     ]
    }
   ],
   "source": [
    "# Train the weak model\n",
    "wk_train_num_samples = 1000000\n",
    "optimizer = AdamW(wk_model.finetune.parameters(), lr=1e-3)\n",
    "gt_to_wk_trainer = SamplingTrainer(model=wk_model, optimizer=optimizer, loss_fn=binary_cross_entropy, data_sampler=gt_data_sampler)\n",
    "gt_to_wk_trainer.train(num_samples=wk_train_num_samples, batch_size=64, average_window=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the strong model using the weak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wk data sampler\n",
    "wk_data_sampler = SyntheticDataSampler(model=wk_model, input_dim=input_dim, output_dim=task_output_dim, var=var)\n",
    "wk_data_sampler.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model device for training: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31250/31250 [01:29<00:00, 350.91it/s, loss=0.027] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Train the strong model - this uses the proper loss function for our misfit inequality\n",
    "st_train_num_samples=2000000\n",
    "optimizer = AdamW(st_model.finetune.parameters(), lr=1e-3)\n",
    "st_to_wk_trainer = SamplingTrainer(model=st_model, optimizer=optimizer, loss_fn=reverse_loss(logistic_bregman_binary), data_sampler=wk_data_sampler, use_label_logits=True)\n",
    "st_to_wk_trainer.train(num_samples=st_train_num_samples, batch_size=64, average_window=10)\n",
    "\n",
    "# Train the strong model - this uses cross-entropy. It does not obey our misfit inequality, but still seems to work. Why?\n",
    "# st_train_num_samples=2000000\n",
    "# optimizer = AdamW(st_model.finetune.parameters(), lr=1e-3)\n",
    "# st_to_wk_trainer = SamplingTrainer(model=st_model, optimizer=optimizer, loss_fn=binary_cross_entropy, data_sampler=wk_data_sampler)\n",
    "# st_to_wk_trainer.train(num_samples=st_train_num_samples, batch_size=64, average_window=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate misfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model device for synthetic data generation: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataBatch(x=tensor([[ 1.0738,  0.3794,  0.6472,  ...,  1.0327, -0.6142,  0.8089],\n",
       "        [-1.1780, -0.4867,  0.8217,  ..., -0.2647,  0.0819, -1.3179],\n",
       "        [-0.5802,  0.2627, -1.2674,  ...,  0.5013,  1.5323, -0.6210],\n",
       "        ...,\n",
       "        [ 0.2662, -1.5649,  1.1858,  ...,  0.3926,  0.5386, -0.6818],\n",
       "        [ 0.6524, -0.5471, -0.8080,  ..., -0.5471, -0.9330, -0.4172],\n",
       "        [-0.0048,  0.6548, -0.2040,  ..., -0.6937, -0.5767,  0.7211]]), y=tensor([[6.5902e-05, 3.0100e-01, 4.6389e-05, 9.9193e-05, 8.0595e-06, 1.7871e-04,\n",
       "         9.9318e-05, 1.5810e-04, 5.9491e-04, 6.9775e-01],\n",
       "        [6.6296e-04, 1.0963e-03, 1.9430e-04, 1.9886e-05, 2.6151e-04, 2.9914e-03,\n",
       "         1.5754e-06, 9.6555e-01, 1.6108e-04, 2.9058e-02],\n",
       "        [6.2568e-07, 5.7398e-01, 2.0274e-07, 6.0367e-07, 1.3372e-06, 5.4663e-06,\n",
       "         2.8296e-10, 8.1377e-08, 8.7887e-04, 4.2513e-01],\n",
       "        [1.2365e-03, 3.7693e-03, 6.1748e-01, 9.8452e-03, 4.8323e-02, 1.4312e-02,\n",
       "         3.1745e-04, 8.2711e-02, 1.0323e-01, 1.1878e-01],\n",
       "        [6.7261e-05, 2.7518e-06, 8.6282e-01, 6.7712e-04, 1.9164e-02, 4.2667e-03,\n",
       "         9.6712e-03, 4.5648e-02, 7.0884e-06, 5.7681e-02],\n",
       "        [5.5597e-04, 1.4833e-03, 1.7417e-01, 1.6352e-01, 1.0272e-03, 6.4141e-01,\n",
       "         2.7826e-05, 4.1876e-04, 8.8411e-04, 1.6501e-02],\n",
       "        [5.5986e-04, 9.5022e-02, 4.9635e-05, 3.9851e-05, 6.7518e-04, 4.5816e-05,\n",
       "         8.7794e-06, 4.1010e-04, 1.3373e-03, 9.0185e-01],\n",
       "        [3.1653e-04, 8.8775e-03, 2.7788e-03, 4.9172e-03, 8.3791e-05, 3.1832e-03,\n",
       "         1.8932e-01, 6.9724e-01, 1.5959e-03, 9.1688e-02],\n",
       "        [6.9118e-03, 2.0115e-02, 3.7281e-03, 1.0302e-03, 5.5360e-03, 2.4996e-02,\n",
       "         1.3466e-03, 6.6455e-01, 1.0937e-05, 2.7178e-01],\n",
       "        [1.0264e-03, 9.3655e-02, 5.9614e-03, 8.8954e-04, 1.5099e-02, 3.6806e-03,\n",
       "         1.0612e-05, 6.5480e-02, 1.6764e-05, 8.1418e-01]]), y_logits=tensor([[ -9.2133,  -0.7867,  -9.5645,  -8.8044, -11.3147,  -8.2157,  -8.8032,\n",
       "          -8.3383,  -7.0131,   0.0541],\n",
       "        [ -5.8457,  -5.3428,  -7.0731,  -9.3524,  -6.7760,  -4.3390, -11.8879,\n",
       "           1.4380,  -7.2605,  -2.0654],\n",
       "        [-12.4651,   1.2642, -13.5920, -12.5009, -11.7056, -10.2976, -20.1664,\n",
       "         -14.5048,  -5.2175,   0.9640],\n",
       "        [ -8.0729,  -6.9583,  -1.8595,  -5.9982,  -4.4072,  -5.6241,  -9.4326,\n",
       "          -3.8698,  -3.6482,  -3.5079],\n",
       "        [-10.8286, -14.0249,  -1.3692,  -8.5193,  -5.1763,  -6.6786,  -5.8602,\n",
       "          -4.3084, -13.0787,  -4.0745],\n",
       "        [ -7.8305,  -6.8492,  -2.0834,  -2.1465,  -7.2166,  -0.7797, -10.8252,\n",
       "          -8.1139,  -7.3666,  -4.4400],\n",
       "        [ -5.9932,  -0.8591,  -8.4163,  -8.6358,  -5.8060,  -8.4963, -10.1485,\n",
       "          -6.3045,  -5.1225,   1.3913],\n",
       "        [ -9.9894,  -6.6555,  -7.8170,  -7.2463, -11.3185,  -7.6812,  -3.5956,\n",
       "          -2.2919,  -8.3716,  -4.3206],\n",
       "        [ -6.7894,  -5.7212,  -7.4067,  -8.6928,  -7.0113,  -5.5039,  -8.4250,\n",
       "          -2.2235, -13.2382,  -3.1176],\n",
       "        [ -6.9582,  -2.4446,  -5.1989,  -7.1012,  -4.2695,  -5.6811, -11.5299,\n",
       "          -2.8024, -11.0727,  -0.2820]]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_data_sampler = SyntheticDataSampler(model=gt_model, input_dim=input_dim, output_dim=task_output_dim, var=var)\n",
    "gt_data_sampler.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1000000/5093263872 [01:20<113:58:24, 12410.93it/s, gt_to_st_xe=1.68, gt_to_wk_xe=1.92, st_to_wk=0.235, wk_to_st=0.218, misfit_xe=-0.00133, gt_to_st=0.954, gt_to_wk=1.19, gt_ent=0.731, st_ent=1.99, wk_ent=1.81, misfit=-0.00133]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached max samples 1000000.\n",
      "Errors: {'gt_to_st_xe': 0.0010214232606813312, 'gt_to_wk_xe': 0.0014456016942858696, 'st_to_wk': 0.00034318119287490845, 'wk_to_st': 0.0003097380104009062, 'misfit_xe': 0.000950468354858458, 'gt_to_st': 0.0008139380370266736, 'gt_to_wk': 0.0013162209652364254, 'gt_ent': 0.001011607819236815, 'st_ent': 0.00032130704494193196, 'wk_ent': 0.0005803710082545877, 'misfit': 0.000950468354858458}\n",
      "{'gt_ent__err': 0.001011607819236815,\n",
      " 'gt_ent__mean': 0.7306965589523315,\n",
      " 'gt_ent__std': 0.5058038830757141,\n",
      " 'gt_to_st__err': 0.0008139380370266736,\n",
      " 'gt_to_st__mean': 0.9535191059112549,\n",
      " 'gt_to_st__std': 0.40696901082992554,\n",
      " 'gt_to_st_xe__err': 0.0010214232606813312,\n",
      " 'gt_to_st_xe__mean': 1.6842186450958252,\n",
      " 'gt_to_st_xe__std': 0.5107116103172302,\n",
      " 'gt_to_wk__err': 0.0013162209652364254,\n",
      " 'gt_to_wk__mean': 1.1871635913848877,\n",
      " 'gt_to_wk__std': 0.6581104397773743,\n",
      " 'gt_to_wk_xe__err': 0.0014456016942858696,\n",
      " 'gt_to_wk_xe__mean': 1.9178581237792969,\n",
      " 'gt_to_wk_xe__std': 0.7228007912635803,\n",
      " 'misfit__err': 0.000950468354858458,\n",
      " 'misfit__mean': -0.0013318016426637769,\n",
      " 'misfit__std': 0.47523415088653564,\n",
      " 'misfit_xe__err': 0.000950468354858458,\n",
      " 'misfit_xe__mean': -0.00133180629927665,\n",
      " 'misfit_xe__std': 0.47523415088653564,\n",
      " 'st_ent__err': 0.00032130704494193196,\n",
      " 'st_ent__mean': 1.992904782295227,\n",
      " 'st_ent__std': 0.1606535166501999,\n",
      " 'st_to_wk__err': 0.00034318119287490845,\n",
      " 'st_to_wk__mean': 0.23497411608695984,\n",
      " 'st_to_wk__std': 0.17159058153629303,\n",
      " 'wk_ent__err': 0.0005803710082545877,\n",
      " 'wk_ent__mean': 1.8096582889556885,\n",
      " 'wk_ent__std': 0.29018548130989075,\n",
      " 'wk_to_st__err': 0.0003097380104009062,\n",
      " 'wk_to_st__mean': 0.21828371286392212,\n",
      " 'wk_to_st__std': 0.15486900508403778}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from src.measurements import EstimateKLMisfit\n",
    "\n",
    "misfit_estimator = EstimateKLMisfit(strong_model=st_model, weak_model=wk_model, data_sampler=gt_data_sampler)\n",
    "result = misfit_estimator.estimate(tolerance=1e-2, batch_size=64, max_samples=1000000)\n",
    "pprint(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pagi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
