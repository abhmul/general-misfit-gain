{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from src.params import RESULTS_DIR, DatasetName, ModelName\n",
    "\n",
    "\n",
    "def load_results():\n",
    "    json_filenames = RESULTS_DIR.glob(\"*.json\")\n",
    "    results = []\n",
    "    for json_filename in json_filenames:\n",
    "        with open(json_filename, \"r\") as f:\n",
    "            results.append(json.load(f))\n",
    "    return results\n",
    "\n",
    "def filter_results(results_list, filter_dict):\n",
    "    filtered_results = [result for result in results_list if all(key in result[\"settings\"] and result[\"settings\"][key] == value for key, value in filter_dict.items())]\n",
    "    return filtered_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vary k test\n",
    "\n",
    "results = load_results()\n",
    "\n",
    "filters = {\n",
    "    \"dataset\": DatasetName.IMAGENET.value,\n",
    "    \"strong_model\": ModelName.VITB8_DINO.value,\n",
    "    # \"exp_id\": \"vary-k-new\",\n",
    "    \"exp_id\": \"w-to-s-new\",\n",
    "    \"num_heads\": \"100\",\n",
    "    \"weight_decay_fixed\": True\n",
    "}\n",
    "\n",
    "filtered_results = filter_results(results, filters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Results: 10\n",
      "defaultdict(<class 'int'>, {'100': 10})\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Should be 5 for Cifar, 4 for imagenet\n",
    "print(f\"Num Results: {len(filtered_results)}\")\n",
    "\n",
    "# Check that there is 1 of each type for num heads\n",
    "num_heads_count = defaultdict(int)\n",
    "for result in filtered_results:\n",
    "    num_heads_count[result[\"settings\"][\"num_heads\"]] += 1\n",
    "\n",
    "print(num_heads_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=100\n",
      "Weak model loss\t1.9258971333503723\t2.843585119694844e-07\n",
      "Weak model acc\t0.5588001608848572\t9.233911862867873e-08\n",
      "Weak model loss r\t1.5178813815116883\t2.636116074025152e-07\n",
      "Weak model acc r\t0.566400146484375\t7.633118912497579e-08\n",
      "Strong model loss\t1.4742154240608216\t0.002815564253154825\n",
      "Strong model misfit\t1.6401374459266662\t0.0023354003413453045\n",
      "Strong model test acc\t0.6986101388931274\t0.0022055672457203393\n",
      "Discrepancy\t-1.1884557366371156\t\n",
      "Strong model loss r\t0.7102438569068908\t0.0018074483135753958\n",
      "Strong model test acc r\t0.7579601585865021\t0.002253075204909093\n",
      "Discrepancy r\t-0.8324999213218688\t\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def display_results_for_nh(results_list):\n",
    "    metrics = [\n",
    "        \"wk<-gt_cross_entropy__mean\",\n",
    "        \"wk<-gt_accuracy__mean\",\n",
    "        \"stgt<-wk_kl_divergence__mean\",\n",
    "        \"stgt<-wk_accuracy__mean\",\n",
    "        \"st<-gt_cross_entropy__mean\",\n",
    "        \"st<-wk_kl_divergence__mean\",\n",
    "        \"st<-gt_accuracy__mean\",\n",
    "        \"stgt<-st_kl_divergence__mean\",\n",
    "        \"stgt<-st_accuracy__mean\",\n",
    "    ]\n",
    "    # Weak model loss r\n",
    "    # Weak model acc r\n",
    "    # Strong model loss  \n",
    "    # Strong model misfit  \n",
    "    # Strong model test acc  \n",
    "    # Discrepancy\n",
    "    # Strong model loss r\n",
    "    # Strong model test acc r\n",
    "    # Discrepancy r\n",
    "\n",
    "    metric_values = defaultdict(lambda: defaultdict(list))\n",
    "    for res in results_list:\n",
    "        for metric in metrics:\n",
    "            metric_values[int(res[\"settings\"][\"num_heads\"])][metric].append(res[\"results\"][metric])\n",
    "    \n",
    "    # Take mean and std of each metric\n",
    "    for _, metric_dict in metric_values.items():\n",
    "        for metric, values in metric_dict.items():\n",
    "            mean = np.mean(values)\n",
    "            std = np.std(values)\n",
    "            metric_dict[metric] = (mean, std)\n",
    "    \n",
    "    # Print the results in the desired form\n",
    "    for num_heads, metric_dict in sorted(metric_values.items(), key=lambda x: x[0]):\n",
    "        print(f\"k={num_heads}\")\n",
    "        print(f\"Weak model loss\\t{metric_dict['wk<-gt_cross_entropy__mean'][0]}\\t{metric_dict['wk<-gt_cross_entropy__mean'][1]}\")\n",
    "        print(f\"Weak model acc\\t{metric_dict['wk<-gt_accuracy__mean'][0]}\\t{metric_dict['wk<-gt_accuracy__mean'][1]}\")\n",
    "        print(f\"Weak model loss r\\t{metric_dict['stgt<-wk_kl_divergence__mean'][0]}\\t{metric_dict['stgt<-wk_kl_divergence__mean'][1]}\")\n",
    "        print(f\"Weak model acc r\\t{metric_dict['stgt<-wk_accuracy__mean'][0]}\\t{metric_dict['stgt<-wk_accuracy__mean'][1]}\")\n",
    "        print(f\"Strong model loss\\t{metric_dict['st<-gt_cross_entropy__mean'][0]}\\t{metric_dict['st<-gt_cross_entropy__mean'][1]}\")\n",
    "        print(f\"Strong model misfit\\t{metric_dict['st<-wk_kl_divergence__mean'][0]}\\t{metric_dict['st<-wk_kl_divergence__mean'][1]}\")\n",
    "        print(f\"Strong model test acc\\t{metric_dict['st<-gt_accuracy__mean'][0]}\\t{metric_dict['st<-gt_accuracy__mean'][1]}\")\n",
    "        discrepancy = metric_dict['wk<-gt_cross_entropy__mean'][0] - metric_dict['st<-wk_kl_divergence__mean'][0]- metric_dict['st<-gt_cross_entropy__mean'][0]\n",
    "        print(f\"Discrepancy\\t{discrepancy}\\t\")\n",
    "        print(f\"Strong model loss r\\t{metric_dict['stgt<-st_kl_divergence__mean'][0]}\\t{metric_dict['stgt<-st_kl_divergence__mean'][1]}\")\n",
    "        print(f\"Strong model test acc r\\t{metric_dict['stgt<-st_accuracy__mean'][0]}\\t{metric_dict['stgt<-st_accuracy__mean'][1]}\")\n",
    "        discrepancy_r = metric_dict['stgt<-wk_kl_divergence__mean'][0] - metric_dict['st<-wk_kl_divergence__mean'][0] - metric_dict['stgt<-st_kl_divergence__mean'][0]\n",
    "        print(f\"Discrepancy r\\t{discrepancy_r}\\t\")\n",
    "\n",
    "display_results_for_nh(filtered_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests for w-to-s-forward\n",
    "results = load_results()\n",
    "\n",
    "filters = {\n",
    "    \"dataset\": DatasetName.CIFAR10.value,\n",
    "    \"strong_model\": ModelName.VITB8_DINO.value,\n",
    "    \"num_heads\": \"100\",\n",
    "    \"exp_id\": \"w-to-s-forward-3\",\n",
    "    \"weight_decay_fixed\": True,\n",
    "}\n",
    "\n",
    "filtered_results = filter_results(results, filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Results: 3\n",
      "defaultdict(<class 'int'>, {'vitb8_dino': 3})\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Should be 2\n",
    "print(f\"Num Results: {len(filtered_results)}\")\n",
    "\n",
    "# Check that there is 1 of each type for model\n",
    "model_count = defaultdict(int)\n",
    "for result in filtered_results:\n",
    "    model_count[result[\"settings\"][\"strong_model\"]] += 1\n",
    "\n",
    "print(model_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vitb8_dino\n",
      "Weak model loss\t0.5824153621991476\t1.2247590229846988e-07\n",
      "Weak model acc\t0.796300212542216\t7.434005313662571e-08\n",
      "Strong model loss\t0.40521153807640076\t0.0021192049083189287\n",
      "Forward-trained Reverse KL misfit\t0.3681456645329793\t0.0017983313355465205\n",
      "Strong model test acc\t0.8981336355209351\t0.0011556690588221707\n",
      "Forward KL Misfit\t0.26816285649935406\t0.00034359007508725554\n",
      "Forward KL Misfit XE\t1.1024143695831299\t0.004544285036629746\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def display_results_for_w_to_s(results_list):\n",
    "    metrics = [\n",
    "        \"wk<-gt_cross_entropy__mean\",\n",
    "        \"wk<-gt_accuracy__mean\",\n",
    "        \"st<-gt_cross_entropy__mean\",\n",
    "        \"st<-wk_kl_divergence__mean\",\n",
    "        \"st<-gt_accuracy__mean\",\n",
    "\n",
    "        # \"stgt<-gt_cross_entropy__mean\",\n",
    "        # \"stgt<-gt_accuracy__mean\",        \n",
    "        # \"stgt<-wk_kl_divergence__mean\",\n",
    "        # \"stgt<-wk_accuracy__mean\",\n",
    "        # \"stgt<-st_kl_divergence__mean\",\n",
    "        # \"stgt<-st_accuracy__mean\",\n",
    "\n",
    "        \"wk<-st_kl_divergence__mean\",\n",
    "        \"wk<-st_cross_entropy__mean\",\n",
    "    ]\n",
    "    # Weak model loss\n",
    "    # Weak model acc\n",
    "    # Strong model loss  \n",
    "    # Strong model misfit  \n",
    "    # Strong model test acc  \n",
    "    # Discrepancy\n",
    "    # Test r acc\n",
    "    # Test r loss\n",
    "    # Weak model loss r\n",
    "    # Weak model acc r\n",
    "    # Strong model loss r\n",
    "    # Strong model test acc r\n",
    "    # Discrepancy r\n",
    "\n",
    "    metric_values = defaultdict(lambda: defaultdict(list))\n",
    "    for res in results_list:\n",
    "        for metric in metrics:\n",
    "            metric_values[res[\"settings\"][\"strong_model\"]][metric].append(res[\"results\"][metric])\n",
    "    \n",
    "    # Take mean and std of each metric\n",
    "    for _, metric_dict in metric_values.items():\n",
    "        for metric, values in metric_dict.items():\n",
    "            mean = np.mean(values)\n",
    "            std = np.std(values)\n",
    "            metric_dict[metric] = (mean, std)\n",
    "    \n",
    "    # Print the results in the desired form\n",
    "    for strong_model, metric_dict in sorted(metric_values.items(), key=lambda x: x[0]):\n",
    "        print(f\"{strong_model}\")\n",
    "        print(f\"Weak model loss\\t{metric_dict['wk<-gt_cross_entropy__mean'][0]}\\t{metric_dict['wk<-gt_cross_entropy__mean'][1]}\")\n",
    "        print(f\"Weak model acc\\t{metric_dict['wk<-gt_accuracy__mean'][0]}\\t{metric_dict['wk<-gt_accuracy__mean'][1]}\")\n",
    "        print(f\"Strong model loss\\t{metric_dict['st<-gt_cross_entropy__mean'][0]}\\t{metric_dict['st<-gt_cross_entropy__mean'][1]}\")\n",
    "        print(f\"Forward-trained Reverse KL misfit\\t{metric_dict['st<-wk_kl_divergence__mean'][0]}\\t{metric_dict['st<-wk_kl_divergence__mean'][1]}\")\n",
    "        print(f\"Strong model test acc\\t{metric_dict['st<-gt_accuracy__mean'][0]}\\t{metric_dict['st<-gt_accuracy__mean'][1]}\")\n",
    "        # discrepancy = metric_dict['wk<-gt_cross_entropy__mean'][0] - metric_dict['st<-wk_kl_divergence__mean'][0]- metric_dict['st<-gt_cross_entropy__mean'][0]\n",
    "        # print(f\"Discrepancy\\t{discrepancy}\\t\")\n",
    "\n",
    "        print(f\"Forward KL Misfit\\t{metric_dict['wk<-st_kl_divergence__mean'][0]}\\t{metric_dict['wk<-st_kl_divergence__mean'][1]}\")\n",
    "        print(f\"Forward KL Misfit XE\\t{metric_dict['wk<-st_cross_entropy__mean'][0]}\\t{metric_dict['wk<-st_cross_entropy__mean'][1]}\")\n",
    "\n",
    "display_results_for_w_to_s(filtered_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests for w-to-s\n",
    "results = load_results()\n",
    "\n",
    "filters = {\n",
    "    \"dataset\": DatasetName.CIFAR10.value,\n",
    "    \"strong_model\": ModelName.VITB8_DINO.value,\n",
    "    \"num_heads\": \"100\",\n",
    "    \"exp_id\": \"w-to-s-new\",\n",
    "    \"weight_decay_fixed\": True,\n",
    "}\n",
    "\n",
    "filtered_results = filter_results(results, filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Results: 3\n",
      "defaultdict(<class 'int'>, {'vitb8_dino': 3})\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Should be 2\n",
    "print(f\"Num Results: {len(filtered_results)}\")\n",
    "\n",
    "# Check that there is 1 of each type for model\n",
    "model_count = defaultdict(int)\n",
    "for result in filtered_results:\n",
    "    model_count[result[\"settings\"][\"strong_model\"]] += 1\n",
    "\n",
    "print(model_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'wk<-st_cross_entropy__mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 74\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mForward KL Misfit XE r\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmetric_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwk<-st_cross_entropy__mean\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmetric_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwk<-st_cross_entropy__mean\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDiscrepancy r\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mdiscrepancy_r\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 74\u001b[0m \u001b[43mdisplay_results_for_w_to_s\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered_results\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 39\u001b[0m, in \u001b[0;36mdisplay_results_for_w_to_s\u001b[0;34m(results_list)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results_list:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m metrics:\n\u001b[0;32m---> 39\u001b[0m         metric_values[res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msettings\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrong_model\u001b[39m\u001b[38;5;124m\"\u001b[39m]][metric]\u001b[38;5;241m.\u001b[39mappend(\u001b[43mres\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresults\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Take mean and std of each metric\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, metric_dict \u001b[38;5;129;01min\u001b[39;00m metric_values\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[0;31mKeyError\u001b[0m: 'wk<-st_cross_entropy__mean'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def display_results_for_w_to_s(results_list):\n",
    "    metrics = [\n",
    "        \"wk<-gt_cross_entropy__mean\",\n",
    "        \"wk<-gt_accuracy__mean\",\n",
    "        \"st<-gt_cross_entropy__mean\",\n",
    "        \"st<-wk_kl_divergence__mean\",\n",
    "        \"st<-gt_accuracy__mean\",\n",
    "\n",
    "        \"stgt<-gt_cross_entropy__mean\",\n",
    "        \"stgt<-gt_accuracy__mean\",        \n",
    "        \"stgt<-wk_kl_divergence__mean\",\n",
    "        \"stgt<-wk_accuracy__mean\",\n",
    "        \"stgt<-st_kl_divergence__mean\",\n",
    "        \"stgt<-st_accuracy__mean\",\n",
    "\n",
    "        # \"wk<-st_kl_divergence__mean\",\n",
    "        \"wk<-st_cross_entropy__mean\",\n",
    "    ]\n",
    "    # Weak model loss\n",
    "    # Weak model acc\n",
    "    # Strong model loss  \n",
    "    # Strong model misfit  \n",
    "    # Strong model test acc  \n",
    "    # Discrepancy\n",
    "    # Test r acc\n",
    "    # Test r loss\n",
    "    # Weak model loss r\n",
    "    # Weak model acc r\n",
    "    # Strong model loss r\n",
    "    # Strong model test acc r\n",
    "    # Discrepancy r\n",
    "\n",
    "    metric_values = defaultdict(lambda: defaultdict(list))\n",
    "    for res in results_list:\n",
    "        for metric in metrics:\n",
    "            metric_values[res[\"settings\"][\"strong_model\"]][metric].append(res[\"results\"][metric])\n",
    "    \n",
    "    # Take mean and std of each metric\n",
    "    for _, metric_dict in metric_values.items():\n",
    "        for metric, values in metric_dict.items():\n",
    "            mean = np.mean(values)\n",
    "            std = np.std(values)\n",
    "            metric_dict[metric] = (mean, std)\n",
    "    \n",
    "    # Print the results in the desired form\n",
    "    for strong_model, metric_dict in sorted(metric_values.items(), key=lambda x: x[0]):\n",
    "        print(f\"{strong_model}\")\n",
    "        print(f\"Weak model loss\\t{metric_dict['wk<-gt_cross_entropy__mean'][0]}\\t{metric_dict['wk<-gt_cross_entropy__mean'][1]}\")\n",
    "        print(f\"Weak model acc\\t{metric_dict['wk<-gt_accuracy__mean'][0]}\\t{metric_dict['wk<-gt_accuracy__mean'][1]}\")\n",
    "        print(f\"Strong model loss\\t{metric_dict['st<-gt_cross_entropy__mean'][0]}\\t{metric_dict['st<-gt_cross_entropy__mean'][1]}\")\n",
    "        print(f\"Strong model misfit\\t{metric_dict['st<-wk_kl_divergence__mean'][0]}\\t{metric_dict['st<-wk_kl_divergence__mean'][1]}\")\n",
    "        print(f\"Strong model test acc\\t{metric_dict['st<-gt_accuracy__mean'][0]}\\t{metric_dict['st<-gt_accuracy__mean'][1]}\")\n",
    "        discrepancy = metric_dict['wk<-gt_cross_entropy__mean'][0] - metric_dict['st<-wk_kl_divergence__mean'][0]- metric_dict['st<-gt_cross_entropy__mean'][0]\n",
    "        print(f\"Discrepancy\\t{discrepancy}\\t\")\n",
    "\n",
    "        print(f\"Test r loss\\t{metric_dict['stgt<-gt_cross_entropy__mean'][0]}\\t{metric_dict['stgt<-gt_cross_entropy__mean'][1]}\")\n",
    "        print(f\"Test r acc\\t{metric_dict['stgt<-gt_accuracy__mean'][0]}\\t{metric_dict['stgt<-gt_accuracy__mean'][1]}\")        \n",
    "        print(f\"Weak model loss r\\t{metric_dict['stgt<-wk_kl_divergence__mean'][0]}\\t{metric_dict['stgt<-wk_kl_divergence__mean'][1]}\")\n",
    "        print(f\"Weak model acc r\\t{metric_dict['stgt<-wk_accuracy__mean'][0]}\\t{metric_dict['stgt<-wk_accuracy__mean'][1]}\")\n",
    "        print(f\"Strong model loss r\\t{metric_dict['stgt<-st_kl_divergence__mean'][0]}\\t{metric_dict['stgt<-st_kl_divergence__mean'][1]}\")\n",
    "        print(f\"Strong model test acc r\\t{metric_dict['stgt<-st_accuracy__mean'][0]}\\t{metric_dict['stgt<-st_accuracy__mean'][1]}\")\n",
    "        discrepancy_r = metric_dict['stgt<-wk_kl_divergence__mean'][0] - metric_dict['st<-wk_kl_divergence__mean'][0] - metric_dict['stgt<-st_kl_divergence__mean'][0]\n",
    "\n",
    "        print(f\"Strong model loss r\\t{metric_dict['stgt<-st_kl_divergence__mean'][0]}\\t{metric_dict['stgt<-st_kl_divergence__mean'][1]}\")\n",
    "        print(f\"Strong model test acc r\\t{metric_dict['stgt<-st_accuracy__mean'][0]}\\t{metric_dict['stgt<-st_accuracy__mean'][1]}\")\n",
    "\n",
    "        # print(f\"Forward KL Misfit r\\t{metric_dict['wk<-st_kl_divergence__mean'][0]}\\t{metric_dict['wk<-st_kl_divergence__mean'][1]}\")\n",
    "        print(f\"Forward KL Misfit XE r\\t{metric_dict['wk<-st_cross_entropy__mean'][0]}\\t{metric_dict['wk<-st_cross_entropy__mean'][1]}\")\n",
    "        print(f\"Discrepancy r\\t{discrepancy_r}\\t\")\n",
    "\n",
    "display_results_for_w_to_s(filtered_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "filters = {\n",
    "    \"dataset\": DatasetName.IMAGENET.value,\n",
    "    \"strong_model\": ModelName.RESNET50_DINO.value,\n",
    "    \"version\": 6.0,\n",
    "    \"num_heads\": '100',\n",
    "    \"debug\": False,\n",
    "    \"exp_id\": \"w-to-s-forward-2\"\n",
    "}\n",
    "# if filters[\"dataset\"] == DatasetName.IMAGENET.value:\n",
    "    # filters[\"version\"] = 3.0\n",
    "\n",
    "\n",
    "\n",
    "filtered_results = filter_results(results, filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Results: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['100', '100', '100', '100', '100', '100', '100', '100', '100', '100']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Num Results: {len(filtered_results)}\")\n",
    "[res[\"settings\"][\"num_heads\"] for res in filtered_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wk<-gt_cross_entropy__mean: 1.9258971571922303 ± 3.5383277129306385e-07\n",
      "wk<-gt_accuracy__mean: 0.5588001310825348 ± 8.940696716308594e-08\n",
      "st<-gt_cross_entropy__mean: 1.648470950126648 ± 0.0039875988601694315\n",
      "st<-wk_kl_divergence__mean: 1.0988789796829224 ± 0.003200920804224958\n",
      "st<-gt_accuracy__mean: 0.6022701621055603 ± 0.002588475704606889\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# GT Error metrics\n",
    "metrics = [\n",
    "    \"wk<-gt_cross_entropy__mean\",\n",
    "    \"wk<-gt_accuracy__mean\",\n",
    "    \"st<-gt_cross_entropy__mean\",\n",
    "    \"st<-wk_kl_divergence__mean\",\n",
    "    \"st<-gt_accuracy__mean\",\n",
    "]\n",
    "\n",
    "# # STGT Error metrics\n",
    "# metrics += [\n",
    "#     \"stgt<-gt_cross_entropy__mean\",\n",
    "#     \"stgt<-gt_accuracy__mean\",\n",
    "#     \"stgt<-st_kl_divergence__mean\",\n",
    "#     \"stgt<-wk_kl_divergence__mean\",\n",
    "#     \"st<-wk_kl_divergence__mean\",\n",
    "#     \"stgt<-st_accuracy__mean\",\n",
    "#     \"stgt<-wk_accuracy__mean\",\n",
    "#     \"st<-wk_accuracy__mean\",\n",
    "# ]\n",
    "\n",
    "# metrics = [\n",
    "#     \"stgt<-wk_kl_divergence__mean\",\n",
    "#     \"stgt<-wk_accuracy__mean\",\n",
    "#     \"st<-gt_cross_entropy__mean\",\n",
    "#     \"st<-wk_kl_divergence__mean\",\n",
    "#     \"st<-gt_accuracy__mean\",\n",
    "#     \"stgt<-st_kl_divergence__mean\",\n",
    "#     \"stgt<-st_accuracy__mean\",\n",
    "# ]\n",
    "\n",
    "def print_metrics(metric_list, results_list):\n",
    "    for metric in metric_list:\n",
    "        print(\"==========\")\n",
    "        print(metric)\n",
    "        for result in results_list:\n",
    "            print(result[\"results\"][metric])\n",
    "\n",
    "# print_metrics(metrics, filtered_results)\n",
    "\n",
    "def get_metric_stats(metric_list, results_list):\n",
    "    extracted_metrics = {}\n",
    "    for metric in metric_list:\n",
    "        extracted_metrics[metric] = np.array([result[\"results\"][metric] for result in results_list], dtype=float)\n",
    "    \n",
    "    stats = {}\n",
    "    for metric, values in extracted_metrics.items():\n",
    "        stats[metric] = {\n",
    "            \"mean\": np.mean(values),\n",
    "            \"std\": np.std(values),\n",
    "        }\n",
    "    return stats\n",
    "\n",
    "# Display the metric stats in a form I can copy and paste\n",
    "def display_metric_stats(metric_stats):\n",
    "    for metric, stats in metric_stats.items():\n",
    "        print(f\"{metric}: {stats['mean']} ± {stats['std']}\")\n",
    "\n",
    "stats = get_metric_stats(metrics, filtered_results)\n",
    "display_metric_stats(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pagi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
